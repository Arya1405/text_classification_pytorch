{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIEpL-XUISkF",
        "outputId": "de2ebcfe-d4f0-4caa-bedc-013b65bc0111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp39-cp39-linux_x86_64.whl (1982.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m820.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp39-cp39-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp39-cp39-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.9.0+cu111) (8.4.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.8.0\n",
            "    Uninstalling torch-1.8.0:\n",
            "      Successfully uninstalled torch-1.8.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.1+cu118\n",
            "    Uninstalling torchaudio-2.0.1+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
          ]
        }
      ],
      "source": [
        "# !pip install torch==1.8.0 torchtext==0.9.0\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PYTORCH Basics\n",
        "\n",
        "A tensor is a data structure or data container we use in PyTorch for carrying arrays of numbers."
      ],
      "metadata": {
        "id": "mWH_JsDmI7OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "5sixT96LgBfZ",
        "outputId": "9805210e-7d97-4d62-c010-c5f82f4cb5ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ec9450a707b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3XMzM-qnIjBj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a tensor from an array\n",
        "array = [[1, 2], [7, 4], [5, 6]]\n",
        "tensor0 = torch.tensor(array)\n",
        "print(tensor0)\n",
        "print(\"The data structure type of tensor0: \", type(tensor0))\n",
        "print(\"The data type of tensor0: \", tensor0.dtype)\n",
        "print(\"The shape of tensor0: \", tensor0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAHnMFgeJGes",
        "outputId": "079002c8-b995-4db5-8d68-2dece8932e25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [7, 4],\n",
            "        [5, 6]])\n",
            "The data structure type of tensor0:  <class 'torch.Tensor'>\n",
            "The data type of tensor0:  torch.int64\n",
            "The shape of tensor0:  torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a tensor from a numpy array\n",
        "np_array = np.array([[1, 2], [7, 4], [5, 6]])\n",
        "tensor1 = torch.tensor(np_array)\n",
        "print(tensor1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOXORuVzJJ86",
        "outputId": "d159887f-2417-4a35-eb2e-b511b07431cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [7, 4],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Slicing"
      ],
      "metadata": {
        "id": "gFJXieOaJV5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensorA = torch.tensor([[1, 1, 1], [2, 2, 2]])\n",
        "tensorB = torch.tensor([[3, 3, 3], [4, 4, 4]])"
      ],
      "metadata": {
        "id": "CtZHnjocJTac"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing is all the same as numpy arrays\n",
        "print('Slicing the first two rows of tensorA (index one inclusive index two exclusive): ')\n",
        "print(tensorA[:2])\n",
        "print('Slicing the first two columns of tensorA (take all rows, then slice columns): ')\n",
        "print(tensorA[:,:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvwiDYLJJag6",
        "outputId": "5568e23a-fa88-4ed0-a7be-8cc96b760bb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slicing the first two rows of tensorA (index one inclusive index two exclusive): \n",
            "tensor([[1, 1, 1],\n",
            "        [2, 2, 2]])\n",
            "Slicing the first two columns of tensorA (take all rows, then slice columns): \n",
            "tensor([[1, 1],\n",
            "        [2, 2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenation"
      ],
      "metadata": {
        "id": "VJQWmaMfJpR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Vertically concatenate tensorA and tensorB: (default: dim=0)')\n",
        "concat_v = torch.cat([tensorA, tensorB]) \n",
        "print(concat_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QZXXQOTJl0t",
        "outputId": "57c699db-6eea-456e-c832-ab6b3ae84094"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertically concatenate tensorA and tensorB: (default: dim=0)\n",
            "tensor([[1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [4, 4, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Horizontally concatenate tensorA and tensorB: (dim=1)')\n",
        "concat_h = torch.cat([tensorA, tensorB], dim = 1) \n",
        "print(concat_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxsXHhOVJyB8",
        "outputId": "a17daec5-c4db-4ae9-d8b8-2711ec77dc17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Horizontally concatenate tensorA and tensorB: (dim=1)\n",
            "tensor([[1, 1, 1, 3, 3, 3],\n",
            "        [2, 2, 2, 4, 4, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing text dataset"
      ],
      "metadata": {
        "id": "H-Mj5osKKNPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import data, datasets\n",
        "import random"
      ],
      "metadata": {
        "id": "Byq6rOghJ3nT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 966\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGAYvytbKQT3",
        "outputId": "a140392a-f0f1-4410-aa34-c71549106113"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fields"
      ],
      "metadata": {
        "id": "8j5v4uu9K2J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator, LabelField"
      ],
      "metadata": {
        "id": "wPg1CDIkTx7A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.datasets  import TREC"
      ],
      "metadata": {
        "id": "3TzfPsHSXejW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = Field(tokenize = 'spacy', lower = True)\n",
        "LABEL = LabelField()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXq2qzLkV9FY",
        "outputId": "fdd413d2-cfe3-4eb4-e237-b99a61b2d73f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = TREC.splits(TEXT, LABEL)\n",
        "train, val = train.split(random_state=random.seed(seed))"
      ],
      "metadata": {
        "id": "IUta-KFIWUel"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vars(train[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFPQuJgqXAm0",
        "outputId": "9ddf41ab-3f17-4183-bbc0-24fd5011025a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['how', 'do', 'you', 'say', '2', 'in', 'latin', '?'], 'label': 'ENTY'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "TEXT.build_vocab(train, min_freq=2)\n",
        "LABEL.build_vocab(train)"
      ],
      "metadata": {
        "id": "5FUXHqJfYNAw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary size of TEXT:\",len(TEXT.vocab.stoi))\n",
        "print(\"Vocabulary size of LABEL:\",len(LABEL.vocab.stoi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eXw7GAFYpyS",
        "outputId": "4bc4350f-372f-4f2f-f67b-411a54e0a388"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size of TEXT: 2643\n",
            "Vocabulary size of LABEL: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train, val, test),\n",
        "    batch_size = 64,\n",
        "    sort_key=lambda x: len(x.text), \n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "FLKM0rq0YveP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a simple CNN model"
      ],
      "metadata": {
        "id": "FYCSYdEea21F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "_ROr3sDbY8rm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model uses an embedding layer to represent the input text as dense vectors. It then applies multiple convolutional layers with different filter sizes to capture different n-grams in the text. The outputs of the convolutional layers are pooled using max pooling and concatenated. Finally, the concatenated features are passed through a fully connected layer to produce the output predictions."
      ],
      "metadata": {
        "id": "Y77_ZZKHb3OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocabulary_size, embedding_size, \n",
        "               kernels_number, kernel_sizes, output_size, dropout_rate):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
        "    self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=kernels_number, kernel_size=(k, embedding_size)) \n",
        "                                            for k in kernel_sizes])\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.fully_connected = nn.Linear(len(kernel_sizes) * kernels_number, output_size)\n",
        "  def forward(self, text):\n",
        "    text = text.permute(1, 0)\n",
        "    input_embeddings = self.embedding(text)\n",
        "    input_embeddings = input_embeddings.unsqueeze(1)\n",
        "    conved = [F.relu(convolution_layer(input_embeddings)).squeeze(3) for convolution_layer in self.convolution_layers]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    concat = self.dropout(torch.cat(pooled, dim=1))\n",
        "    final_output = self.fully_connected(concat)\n",
        "    return final_output"
      ],
      "metadata": {
        "id": "Yg_l0jg2bPyX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(TEXT.vocab)\n",
        "embedding_size = 100\n",
        "kernels_number = 100\n",
        "kernel_sizes = [2, 3, 4]\n",
        "output_size = len(LABEL.vocab)\n",
        "dropout_rate = 0.3"
      ],
      "metadata": {
        "id": "Wo0EFH66bUZ6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(input_size, embedding_size, kernels_number, kernel_sizes, output_size, dropout_rate)"
      ],
      "metadata": {
        "id": "CShJZz95bYAr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyk9qtLgbgYV",
        "outputId": "b6ff5b0f-78af-432f-f497-133850d26db0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (embedding): Embedding(2643, 100)\n",
            "  (convolution_layers): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fully_connected): Linear(in_features=300, out_features=6, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VagHbA-bbij3",
        "outputId": "e37b3225-3419-4568-c64c-ee9d832c7f39"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embedding): Embedding(2643, 100)\n",
              "  (convolution_layers): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))\n",
              "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
              "    (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fully_connected): Linear(in_features=300, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate Functions"
      ],
      "metadata": {
        "id": "0b4faTzxb-AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Rc5ovttpbpiy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "uOQoOTtQcGHn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(predictions, actual_label):\n",
        "    max_predictions = predictions.argmax(dim = 1, keepdim = True, )\n",
        "    correct_predictions = max_predictions.squeeze(1).eq(actual_label)\n",
        "    accuracy = correct_predictions.sum() / torch.cuda.FloatTensor([actual_label.shape[0]])\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "lZ6H9Iuecp3D"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "hmVO8bWqcska"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "lixeALNxcvLw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "mDv6j_jweHLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_epochs = 20\n",
        "\n",
        "best_acc = float('-inf')\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "    \n",
        "    # Write the code here\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    # Write the code here\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_acc > best_acc:\n",
        "        # Write the code here\n",
        "        best_acc = valid_acc\n",
        "        torch.save(model.state_dict(), 'trec.pt')\n",
        "    \n",
        "    print(f'Epoch {epoch+1} ')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Validation Loss: {valid_loss:.3f} |  Validation Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otu_fLDDcyVQ",
        "outputId": "686c213f-6831-4d55-b995-d8c03f25197c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "\tTrain Loss: 1.308 | Train Acc: 47.92%\n",
            "\t Validation Loss: 0.956 |  Validation Acc: 64.57%\n",
            "Epoch 2 \n",
            "\tTrain Loss: 0.788 | Train Acc: 71.94%\n",
            "\t Validation Loss: 0.736 |  Validation Acc: 72.54%\n",
            "Epoch 3 \n",
            "\tTrain Loss: 0.600 | Train Acc: 79.30%\n",
            "\t Validation Loss: 0.637 |  Validation Acc: 75.61%\n",
            "Epoch 4 \n",
            "\tTrain Loss: 0.465 | Train Acc: 84.93%\n",
            "\t Validation Loss: 0.615 |  Validation Acc: 75.99%\n",
            "Epoch 5 \n",
            "\tTrain Loss: 0.361 | Train Acc: 89.19%\n",
            "\t Validation Loss: 0.554 |  Validation Acc: 78.60%\n",
            "Epoch 6 \n",
            "\tTrain Loss: 0.279 | Train Acc: 91.90%\n",
            "\t Validation Loss: 0.532 |  Validation Acc: 80.71%\n",
            "Epoch 7 \n",
            "\tTrain Loss: 0.210 | Train Acc: 94.14%\n",
            "\t Validation Loss: 0.514 |  Validation Acc: 80.63%\n",
            "Epoch 8 \n",
            "\tTrain Loss: 0.168 | Train Acc: 95.81%\n",
            "\t Validation Loss: 0.522 |  Validation Acc: 81.67%\n",
            "Epoch 9 \n",
            "\tTrain Loss: 0.140 | Train Acc: 96.45%\n",
            "\t Validation Loss: 0.515 |  Validation Acc: 82.38%\n",
            "Epoch 10 \n",
            "\tTrain Loss: 0.113 | Train Acc: 97.48%\n",
            "\t Validation Loss: 0.509 |  Validation Acc: 82.38%\n",
            "Epoch 11 \n",
            "\tTrain Loss: 0.090 | Train Acc: 98.12%\n",
            "\t Validation Loss: 0.514 |  Validation Acc: 82.16%\n",
            "Epoch 12 \n",
            "\tTrain Loss: 0.075 | Train Acc: 98.61%\n",
            "\t Validation Loss: 0.520 |  Validation Acc: 82.20%\n",
            "Epoch 13 \n",
            "\tTrain Loss: 0.064 | Train Acc: 98.47%\n",
            "\t Validation Loss: 0.515 |  Validation Acc: 82.51%\n",
            "Epoch 14 \n",
            "\tTrain Loss: 0.054 | Train Acc: 98.99%\n",
            "\t Validation Loss: 0.541 |  Validation Acc: 82.10%\n",
            "Epoch 15 \n",
            "\tTrain Loss: 0.050 | Train Acc: 98.97%\n",
            "\t Validation Loss: 0.529 |  Validation Acc: 82.81%\n",
            "Epoch 16 \n",
            "\tTrain Loss: 0.042 | Train Acc: 99.23%\n",
            "\t Validation Loss: 0.543 |  Validation Acc: 82.96%\n",
            "Epoch 17 \n",
            "\tTrain Loss: 0.037 | Train Acc: 99.27%\n",
            "\t Validation Loss: 0.529 |  Validation Acc: 82.98%\n",
            "Epoch 18 \n",
            "\tTrain Loss: 0.032 | Train Acc: 99.27%\n",
            "\t Validation Loss: 0.559 |  Validation Acc: 82.79%\n",
            "Epoch 19 \n",
            "\tTrain Loss: 0.033 | Train Acc: 99.22%\n",
            "\t Validation Loss: 0.559 |  Validation Acc: 82.33%\n",
            "Epoch 20 \n",
            "\tTrain Loss: 0.030 | Train Acc: 99.27%\n",
            "\t Validation Loss: 0.555 |  Validation Acc: 83.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('trec.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSCEU8treMB_",
        "outputId": "33a6f5a5-9bb3-4122-dc70-07999af180ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.422 | Test Acc: 89.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jav17FDTesHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}